{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn import model_selection, preprocessing as pp\n",
    "from sklearn.metrics import classification_report, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.externals import joblib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of the typical meteorological year (tmy) dataset\n",
    "#download the file from nrel if interested\n",
    "filename_tmy = os.path.join(\"tmy3MSPairport.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the dataset we're using is the Typical Meteorological Year dataset from NREL.  \n",
    "\n",
    "The TMY3 dataset is a year's worth of hourly meteorological data, by location.\n",
    "It is derived from the 1961-1990 and 1991-2005 National Solar Radiation Database  archives.  Each month of the year is the month that is determined to be \"most typical\" from all of the data in the archive.  You can read more about the TMY datasets here: https://rredc.nrel.gov/solar/old_data/nsrdb/1991-2005/tmy3/.\n",
    "\n",
    "There are a few limitations of this dataset:\n",
    "\n",
    "1. It is a \"typical\" meteorological year, therefore, it won't help in dealing with extremes and worst case scenerios.\n",
    "2. It is relatively small at 8760 points.  On a related note, because it is just one year of data, the annual seasonality of average solar irradiance is seen as an upwards trend until (roughly) the summer solstice, followed by a downward trend until (roughly) the winter solstice rather than the roughly sinusoidal signal that would be observed over multiple years.\n",
    "\n",
    "In spite of these drawbacks, I believe this is a good dataset to start with.  It is currently being used in modelling monthly generation for use in Power Purchase Agreements (PPA), is decently comprehensive and is organized by location for over 1000 sites.  In addition, this was my first project, and one year's worth of data seemed to be a bit easier to chew than 10 or more times that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmy_df = pd.read_csv(filename_tmy, header=1, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (MM/DD/YYYY)</th>\n",
       "      <th>Time (HH:MM)</th>\n",
       "      <th>ETR (W/m^2)</th>\n",
       "      <th>ETRN (W/m^2)</th>\n",
       "      <th>GHI (W/m^2)</th>\n",
       "      <th>GHI source</th>\n",
       "      <th>GHI uncert (%)</th>\n",
       "      <th>DNI (W/m^2)</th>\n",
       "      <th>DNI source</th>\n",
       "      <th>DNI uncert (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>Alb (unitless)</th>\n",
       "      <th>Alb source</th>\n",
       "      <th>Alb uncert (code)</th>\n",
       "      <th>Lprecip depth (mm)</th>\n",
       "      <th>Lprecip quantity (hr)</th>\n",
       "      <th>Lprecip source</th>\n",
       "      <th>Lprecip uncert (code)</th>\n",
       "      <th>PresWth (METAR code)</th>\n",
       "      <th>PresWth source</th>\n",
       "      <th>PresWth uncert (code)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>1:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>2:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>3:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>4:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2004</td>\n",
       "      <td>5:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (MM/DD/YYYY) Time (HH:MM)  ETR (W/m^2)  ETRN (W/m^2)  GHI (W/m^2)  \\\n",
       "0          1/1/2004         1:00            0             0            0   \n",
       "1          1/1/2004         2:00            0             0            0   \n",
       "2          1/1/2004         3:00            0             0            0   \n",
       "3          1/1/2004         4:00            0             0            0   \n",
       "4          1/1/2004         5:00            0             0            0   \n",
       "\n",
       "   GHI source  GHI uncert (%)  DNI (W/m^2)  DNI source  DNI uncert (%)  \\\n",
       "0           2               0            0           2               0   \n",
       "1           2               0            0           2               0   \n",
       "2           2               0            0           2               0   \n",
       "3           2               0            0           2               0   \n",
       "4           2               0            0           2               0   \n",
       "\n",
       "           ...            Alb (unitless)  Alb source  Alb uncert (code)  \\\n",
       "0          ...                         0           F                  8   \n",
       "1          ...                         0           F                  8   \n",
       "2          ...                         0           F                  8   \n",
       "3          ...                         0           F                  8   \n",
       "4          ...                         0           F                  8   \n",
       "\n",
       "   Lprecip depth (mm)  Lprecip quantity (hr)  Lprecip source  \\\n",
       "0                   0                      1               D   \n",
       "1                   0                      1               D   \n",
       "2                   0                      1               D   \n",
       "3                   0                      1               D   \n",
       "4                   0                      1               D   \n",
       "\n",
       "   Lprecip uncert (code)  PresWth (METAR code)  PresWth source  \\\n",
       "0                      9                     0               C   \n",
       "1                      9                     0               C   \n",
       "2                      9                     0               C   \n",
       "3                      9                     0               C   \n",
       "4                      9                     0               C   \n",
       "\n",
       "   PresWth uncert (code)  \n",
       "0                      8  \n",
       "1                      8  \n",
       "2                      8  \n",
       "3                      8  \n",
       "4                      8  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look at the first few rows of the dataset.  \n",
    "\n",
    "It isn't shown here, but each month has a different year since each month has been \"selected\" as being the most typical. \n",
    "\n",
    "Again, hourly data.\n",
    "\n",
    "The columns we will be concerned with mostly in this are ETR (Extraterrestrial Radiation), DNI (Direct Normal Irradiance) and DHI (Diffuse Horizontal Irradiance).  In short, ETR indicates the amount of solar radiation above the weather (extraterrestrial).  DNI, or beam irradiance, is the sunlight hitting a reflector directly, at a perpendicular angle.  DHI, or diffuse irradiance is the photons that are scattered due to particulate matter in the atmosphere.\n",
    "\n",
    "NOTE: System generation is very close to being linearly related to the total irradiance (DNI + DHI), so the sum of those together, rather than evaluating each individually is probably a better path forward in the future.\n",
    "\n",
    "The weather data we will be concerned with is the TotCld (cloud coverage), Dry-bulb (temperature), and RHum (relative humidity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmy_weather = tmy_df[['ETR (W/m^2)', 'GHI (W/m^2)', 'DNI (W/m^2)', 'DHI (W/m^2)', \n",
    "'TotCld (tenths)', 'Dry-bulb (C)', 'RHum (%)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will convert the dataframe to an array and split it into DNI and DHI datasets, as we will be training and evaluating the model on each of those separately.  We will also hold 20% of the data back in order to validate our model later.\n",
    "\n",
    "While it is not implemented in this project, in other projects of mine, I've used ETR as a sort of \"night time\" flag.  Sometimes there can be 0 irradiance during the day because of thick clouds, but ETR would still be positive.  However, if ETR is 0, we can tell the model that there is no possible irradiance, and set the prediction to 0.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmy_weather_a = tmy_weather.values\n",
    "#X values are all rows in ETR (sort of like time of day), Clouds, Temp, Relative Humidity\n",
    "X = tmy_weather_a[:, [0, 4, 5, 6]]\n",
    "#Y values are just DNI and DHI: direct and diffuse irradiance\n",
    "Y = tmy_weather_a[:, [2, 3]]\n",
    "#split once further:\n",
    "DNI_Y = Y[:, 0]\n",
    "DHI_Y = Y[:, 1]\n",
    "#Note that both models will use the same X, or input data\n",
    "\n",
    "#20% held back for validation\n",
    "validation_size = 0.20\n",
    "#initialize random seed for reproducibility\n",
    "DNI_seed = 7\n",
    "DHI_seed = 5\n",
    "#train_test_split the data randomly into training and testing sets\n",
    "X_train, X_val, DNI_Y_train, DNI_Y_val = model_selection.train_test_split(X, DNI_Y, test_size=validation_size, random_state=DNI_seed)\n",
    "X_train, X_val, DHI_Y_train, DHI_Y_val = model_selection.train_test_split(X, DHI_Y, test_size=validation_size, random_state=DHI_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, anyone following along who knows a thing or two about data science / machine learning will realize that randomizing the data is not a good idea, since this is quite clearly a time series forecasting problem.  It's a place to start in this case.\n",
    "\n",
    "Next, we'll standardize all of the data.  Using sklearn's StandardScaler(), we get data with a mean of 0 and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standardizer = pp.StandardScaler()\n",
    "DNI_Y_standardizer = pp.StandardScaler()\n",
    "DHI_Y_standardizer = pp.StandardScaler()\n",
    "\n",
    "#note that the 1 dimensional y array needs to be reshaped for the function to \n",
    "#operate properly\n",
    "DNI_Y_train = np.array(DNI_Y_train).reshape((len(DNI_Y_train), 1))\n",
    "DHI_Y_train = np.array(DHI_Y_train).reshape((len(DHI_Y_train), 1))\n",
    "\n",
    "X_train_scaled = X_standardizer.fit_transform(X_train)\n",
    "DNI_Y_train_scaled = DNI_Y_standardizer.fit_transform(DNI_Y_train)\n",
    "DHI_Y_train_scaled = DHI_Y_standardizer.fit_transform(DHI_Y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to train and evaluate the model.  I went with a Support Vector Regression model, after finding it had the best results, but admittedly, at that time, I didn't really know what that meant.  In later posts I will explore both a time series analysis with an ARIMA model as well as a LSTM neural network, and likely some other classical models such as decision trees, linear regression, logistic regression, etc.\n",
    "\n",
    "We'll use 10 fold cross validation with mean absolute error and R squared as our evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['neg_mean_absolute_error', 'r2']\n",
    "kfolds = 10\n",
    "model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNI: \n",
      "neg_mean_absolute_error mean:  -170.48493870006075\n",
      "neg_mean_absolute_error stdev:  11.6201121481729\n",
      "r2 mean:  -0.3746117178631775\n",
      "r2 stdev:  0.031553171110808555\n",
      "DHI: \n",
      "neg_mean_absolute_error mean:  -64.42495128473288\n",
      "neg_mean_absolute_error stdev:  1.7290716717993322\n",
      "r2 mean:  -0.31608475507340883\n",
      "r2 stdev:  0.021089446201420142\n"
     ]
    }
   ],
   "source": [
    "def trainer(X_data, Y_data, seed, kfolds):\n",
    "    kfold = model_selection.KFold(n_splits=kfolds, random_state=seed)\n",
    "    #evaluate for each scoring metric\n",
    "    for i, method in enumerate(scores):\n",
    "        #note, .ravel() is used on the Y_data since we reshaped it earlier in order\n",
    "        #to fit into the scaler. Ravel brings it back to its original dimensionality.\n",
    "        cv_results = model_selection.cross_val_score(model, \n",
    "                                                     X_data,\n",
    "                                                     Y_data.ravel(),\n",
    "                                                     cv=kfold,\n",
    "                                                     scoring=method)\n",
    "        print(scores[i] + ' mean: ', cv_results.mean())\n",
    "        print(scores[i] + ' stdev: ', cv_results.std())\n",
    "\n",
    "print('DNI: ')       \n",
    "trainer(X_train, DNI_Y_train, DNI_seed, kfolds)\n",
    "print('DHI: ')\n",
    "trainer(X_train, DHI_Y_train, DHI_seed, kfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, our DNI predictions were off by 170.5 W/m^2 and our DHI values by 64.4.  The R squared value does not indicate a particularly good fit.  \n",
    "\n",
    "Much of this could be likely be improved simply by accounting for night time, which we are not currently doing, and will be shown more explicitly shortly.  \n",
    "\n",
    "Next, we'll run this model on our validation dataset, which is \"unseen\" to the model.  This is a sort of test run, before we send the model out into the real world, although this model won't be going anywhere anytime soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale validation data\n",
    "X_val_scaled = X_standardizer.fit_transform(X_val)\n",
    "DNI_Y_val = np.array(DNI_Y_val).reshape((len(DNI_Y_val), 1))\n",
    "DHI_Y_val = np.array(DHI_Y_val).reshape((len(DHI_Y_val), 1))\n",
    "DNI_Y_val_scaled = DNI_Y_standardizer.fit_transform(DNI_Y_val)\n",
    "DHI_Y_val_scaled = DHI_Y_standardizer.fit_transform(DHI_Y_val)\n",
    "\n",
    "#define, fit models\n",
    "SVM_DNI = SVR()\n",
    "SVM_DHI = SVR()\n",
    "SVM_DNI.fit(X_val_scaled, DNI_Y_val_scaled.ravel())\n",
    "SVM_DHI.fit(X_val_scaled, DHI_Y_val_scaled.ravel())\n",
    "\n",
    "\n",
    "#make predictions\n",
    "predictions_DNI = SVM_DNI.predict(X_val_scaled)\n",
    "predictions_DHI = SVM_DHI.predict(X_val_scaled)\n",
    "\n",
    "predictions_DNI = np.array(predictions_DNI).reshape((len(predictions_DNI), 1))\n",
    "predictions_DHI = np.array(predictions_DHI).reshape((len(predictions_DHI), 1))\n",
    "\n",
    "#invert the predictions back to normal scale\n",
    "predictions_DNI_inverted = DNI_Y_standardizer.inverse_transform(predictions_DNI)\n",
    "predictions_DHI_inverted = DHI_Y_standardizer.inverse_transform(predictions_DHI)\n",
    "X_validation_inverted = X_standardizer.fit_transform(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for DNI predictions: \n",
      "182.0650567127503\n",
      "MAE for DHI predictions: \n",
      "15.302799766543252\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE for DNI predictions: \")\n",
    "print(mean_absolute_error(DNI_Y_val, predictions_DNI_inverted))\n",
    "print(\"MAE for DHI predictions: \")\n",
    "print(mean_absolute_error(DHI_Y_val, predictions_DHI_inverted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DHI:</th>\n",
       "      <th>DNI:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[43.61546279705216]</td>\n",
       "      <td>[28.971766623758896]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[157.5277992893514]</td>\n",
       "      <td>[28.922890622505804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7.498861590925991]</td>\n",
       "      <td>[31.66642194249488]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[358.45724160839194]</td>\n",
       "      <td>[28.94301905330488]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2.167354164775354]</td>\n",
       "      <td>[28.994463593440514]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[8.216939259254865]</td>\n",
       "      <td>[28.747784394130775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[7.774946717283768]</td>\n",
       "      <td>[28.68043531553826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[7.607161200108457]</td>\n",
       "      <td>[27.329066109501667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[16.569607786379763]</td>\n",
       "      <td>[29.309344546088397]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[255.40240817826472]</td>\n",
       "      <td>[29.745066928385853]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[7.019006251256073]</td>\n",
       "      <td>[32.74692946572057]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[291.86858968009625]</td>\n",
       "      <td>[28.423564428496718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[5.27953840253128]</td>\n",
       "      <td>[28.67191064927505]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[5.365783104211367]</td>\n",
       "      <td>[28.831389480152495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[9.27185102132588]</td>\n",
       "      <td>[30.012323690019173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[101.25375374249589]</td>\n",
       "      <td>[28.013272650631393]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[32.82096141068335]</td>\n",
       "      <td>[28.149843391773118]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[4.8287605648164345]</td>\n",
       "      <td>[29.01140284114203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[5.281238996000994]</td>\n",
       "      <td>[28.209054142045403]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[3.8307449960512017]</td>\n",
       "      <td>[29.319253212813322]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[7.384703415633574]</td>\n",
       "      <td>[29.14132557123125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[326.4690802964754]</td>\n",
       "      <td>[28.543819473798408]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[37.210353198165464]</td>\n",
       "      <td>[29.109402553272503]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[6.595083375356474]</td>\n",
       "      <td>[28.721346837102203]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[7.24885160175257]</td>\n",
       "      <td>[28.91635343581936]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[49.83611064870849]</td>\n",
       "      <td>[29.07340499318684]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[171.15946789503383]</td>\n",
       "      <td>[29.108207394364598]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[5.952302015229044]</td>\n",
       "      <td>[28.210914474507092]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[2.18143146794106]</td>\n",
       "      <td>[28.341262179216073]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[136.10181472910187]</td>\n",
       "      <td>[29.510254294529602]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[2.453865605301665]</td>\n",
       "      <td>[30.858807063686726]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[82.86998138490199]</td>\n",
       "      <td>[40.82001657892431]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[136.57671863919717]</td>\n",
       "      <td>[26.548362682936414]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[157.16156509295834]</td>\n",
       "      <td>[29.3466461461544]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[180.61977052201874]</td>\n",
       "      <td>[28.57576629428192]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[1.3630707321661077]</td>\n",
       "      <td>[32.172586943909636]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[2.8776985105966233]</td>\n",
       "      <td>[28.54805650435057]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[5.653985638219659]</td>\n",
       "      <td>[28.844960545106886]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[-0.010444315942237381]</td>\n",
       "      <td>[28.43219558091181]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[89.3150337597944]</td>\n",
       "      <td>[27.62055842882492]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[139.14469025868397]</td>\n",
       "      <td>[28.72803169696772]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[7.0760928297236845]</td>\n",
       "      <td>[29.306189593396965]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[6.76862175534076]</td>\n",
       "      <td>[32.93203022600653]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[63.605840668567616]</td>\n",
       "      <td>[28.051516863177056]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[201.40377427384243]</td>\n",
       "      <td>[29.297368333793145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[7.929256142273495]</td>\n",
       "      <td>[28.636429065781897]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[194.42604052126418]</td>\n",
       "      <td>[28.858633025625522]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[70.81272520057036]</td>\n",
       "      <td>[32.27784641675552]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[2.5852534095794866]</td>\n",
       "      <td>[32.111958970916646]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[191.9148016021208]</td>\n",
       "      <td>[28.739650041407458]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DHI:                  DNI: \n",
       "0       [43.61546279705216]  [28.971766623758896]\n",
       "1       [157.5277992893514]  [28.922890622505804]\n",
       "2       [7.498861590925991]   [31.66642194249488]\n",
       "3      [358.45724160839194]   [28.94301905330488]\n",
       "4       [2.167354164775354]  [28.994463593440514]\n",
       "5       [8.216939259254865]  [28.747784394130775]\n",
       "6       [7.774946717283768]   [28.68043531553826]\n",
       "7       [7.607161200108457]  [27.329066109501667]\n",
       "8      [16.569607786379763]  [29.309344546088397]\n",
       "9      [255.40240817826472]  [29.745066928385853]\n",
       "10      [7.019006251256073]   [32.74692946572057]\n",
       "11     [291.86858968009625]  [28.423564428496718]\n",
       "12       [5.27953840253128]   [28.67191064927505]\n",
       "13      [5.365783104211367]  [28.831389480152495]\n",
       "14       [9.27185102132588]  [30.012323690019173]\n",
       "15     [101.25375374249589]  [28.013272650631393]\n",
       "16      [32.82096141068335]  [28.149843391773118]\n",
       "17     [4.8287605648164345]   [29.01140284114203]\n",
       "18      [5.281238996000994]  [28.209054142045403]\n",
       "19     [3.8307449960512017]  [29.319253212813322]\n",
       "20      [7.384703415633574]   [29.14132557123125]\n",
       "21      [326.4690802964754]  [28.543819473798408]\n",
       "22     [37.210353198165464]  [29.109402553272503]\n",
       "23      [6.595083375356474]  [28.721346837102203]\n",
       "24       [7.24885160175257]   [28.91635343581936]\n",
       "25      [49.83611064870849]   [29.07340499318684]\n",
       "26     [171.15946789503383]  [29.108207394364598]\n",
       "27      [5.952302015229044]  [28.210914474507092]\n",
       "28       [2.18143146794106]  [28.341262179216073]\n",
       "29     [136.10181472910187]  [29.510254294529602]\n",
       "30      [2.453865605301665]  [30.858807063686726]\n",
       "31      [82.86998138490199]   [40.82001657892431]\n",
       "32     [136.57671863919717]  [26.548362682936414]\n",
       "33     [157.16156509295834]    [29.3466461461544]\n",
       "34     [180.61977052201874]   [28.57576629428192]\n",
       "35     [1.3630707321661077]  [32.172586943909636]\n",
       "36     [2.8776985105966233]   [28.54805650435057]\n",
       "37      [5.653985638219659]  [28.844960545106886]\n",
       "38  [-0.010444315942237381]   [28.43219558091181]\n",
       "39       [89.3150337597944]   [27.62055842882492]\n",
       "40     [139.14469025868397]   [28.72803169696772]\n",
       "41     [7.0760928297236845]  [29.306189593396965]\n",
       "42       [6.76862175534076]   [32.93203022600653]\n",
       "43     [63.605840668567616]  [28.051516863177056]\n",
       "44     [201.40377427384243]  [29.297368333793145]\n",
       "45      [7.929256142273495]  [28.636429065781897]\n",
       "46     [194.42604052126418]  [28.858633025625522]\n",
       "47      [70.81272520057036]   [32.27784641675552]\n",
       "48     [2.5852534095794866]  [32.111958970916646]\n",
       "49      [191.9148016021208]  [28.739650041407458]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at the actual values:\n",
    "pred_df = pd.DataFrame({\n",
    "    'DNI: ': predictions_DNI_inverted.tolist(),\n",
    "    'DHI: ': predictions_DHI_inverted.tolist()\n",
    "})\n",
    "pred_df.head(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data was randomized during the train test split, there's only so much we can extract from these predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's going to be the end of this quick little intro to my humble start in this realm.  Some improvements that will be documented in the near future:\n",
    "\n",
    "1. Taking into account the temporal structure of the data.\n",
    "2. More Visualization of the data in general\n",
    "3. Different models (ARIMA, decision trees, LSTM neural networks)\n",
    "4. More Data - Pulling from the NSRDB rather than just using TMY.  This will give us access to years and years of data rather than just the one, combined set.\n",
    "5. Making predictions on real out of sample data - shortly, I will show my program for pulling from the National Digital Forecast Database API, but there are many, many weather databases to choose from all with different strengths and weaknesses.\n",
    "\n",
    "I'm sure there's more to improve, but this is a good jumping off point I think, and stumbling through the project six months ago really helped me get an idea of what machine learning is and what it can do.  Thanks for reading, and I'll see you next time :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
